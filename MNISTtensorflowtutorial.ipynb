{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86555aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist_data/train-images-idx3-ubyte.gz\n",
      "Extracting mnist_data/train-labels-idx1-ubyte.gz\n",
      "Extracting mnist_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\N\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Test Accuracy: 90.49000144004822%\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() \n",
    "\n",
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "#mnist = input_data.read_data_sets(\"MNIST/\", one_hot = True)\n",
    "\n",
    "import input_data\n",
    "\n",
    "\n",
    "",
    "mnist = input_data.read_data_sets(\"mnist_data/\", one_hot=True)\n",
    "    \n",
    "# x is placeholder for the 28 X 28 image data\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "\n",
    "# y_ is called \"y bar\" and is a 10 element vector, containing the predicted probability of each \n",
    "#   digit(0-9) class.  Such as [0.14, 0.8, 0,0,0,0,0,0,0, 0.06]\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])  \n",
    "\n",
    "# define weights and balances\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# define our inference model\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "\n",
    "# loss is cross entropy\n",
    "cross_entropy = tf.reduce_mean(\n",
    "                tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "\n",
    "# each training step in gradient decent we want to minimize cross entropy\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "# initialize the global variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# create an interactive session that can span multiple code blocks.  Don't \n",
    "# forget to explicity close the session with sess.close()\n",
    "sess = tf.Session()\n",
    "\n",
    "# perform the initialization which is only the initialization of all global variables\n",
    "sess.run(init)\n",
    "\n",
    "# Perform 1000 training steps\n",
    "for i in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)    # get 100 random data points from the data. batch_xs = image, \n",
    "                                                        # batch_ys = digit(0-9) class\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys}) # do the optimization with this data\n",
    "\n",
    "# Evaluate how well the model did. Do this by comparing the digit with the highest probability in \n",
    "#    actual (y) and predicted (y_).\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "test_accuracy = sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "print(\"Test Accuracy: {0}%\".format(test_accuracy * 100.0))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa24791",
   "metadata": {},
   "source": [
    "Note : I encountered The \"ModuleNotFoundError: No module named 'tensorflow.examples' \" this is because \"tensorflow.examples.tutorials\" module is not included in the pip package. \n",
    "\n",
    "You will find it in TF's GitHub repo. \n",
    "! git clone https://github.com/tensorflow/tensorflow.git the Tensorflow GitHub repo and in the downloaded folders locate where the input_data.py file is then copy and paste it in the working directory of your project then import input_data on your python terminal, it will sort it out for you.\n",
    "Thanks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fee0709",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
